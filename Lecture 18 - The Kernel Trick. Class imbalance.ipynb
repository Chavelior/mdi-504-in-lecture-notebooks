{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# ----- make nice figures -----\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.dpi']= 150\n",
    "# -----------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.loadtxt('perovskite_data.txt')\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = data[:, 0]\n",
    "X = data[:, 1:15]\n",
    "\n",
    "C_train = C[0:280]\n",
    "X_train = X[0:280,:]\n",
    "\n",
    "C_valid = C[280:]\n",
    "X_valid = X[280:, :]\n",
    "\n",
    "# normalize data\n",
    "mu_X = np.mean(X_train)\n",
    "sig_X = np.std(X_train)\n",
    "X_train = (X_train - mu_X)/sig_X\n",
    "X_valid = (X_valid - mu_X)/sig_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# This is how you specify which kernel to use\n",
    "linear_svm_model = SVC(kernel=\"linear\")\n",
    "\n",
    "# train the model - note we don't have have to form a design matrix\n",
    "linear_svm_model.fit(X_train, C_train)\n",
    "\n",
    "# Predict validation data\n",
    "C_valid_model = linear_svm_model.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision and recall. We'll use the functions in sklearn.metrics\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "precision = precision_score(C_valid, C_valid_model)\n",
    "recall = recall_score(C_valid, C_valid_model)\n",
    "\n",
    "print(\"Precision = \" + str(precision))\n",
    "print(\"Recall = \" + str(recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# polynomial kernel\n",
    "poly_svm_model = SVC(kernel=\"poly\", degree=3)\n",
    "\n",
    "# train the model - note we don't have have to form a design matrix\n",
    "poly_svm_model.fit(X_train, C_train)\n",
    "\n",
    "# Predict validation data\n",
    "C_valid_model = poly_svm_model.predict(X_valid)\n",
    "\n",
    "precision = precision_score(C_valid, C_valid_model)\n",
    "recall = recall_score(C_valid, C_valid_model)\n",
    "\n",
    "print(\"Precision = \" + str(precision))\n",
    "print(\"Recall = \" + str(recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaussian kernel\n",
    "rbf_svm_model = SVC(kernel=\"rbf\")\n",
    "\n",
    "# train the model - note we don't have have to form a design matrix\n",
    "rbf_svm_model.fit(X_train, C_train)\n",
    "\n",
    "# Predict validation data\n",
    "C_valid_model = rbf_svm_model.predict(X_valid)\n",
    "\n",
    "precision = precision_score(C_valid, C_valid_model)\n",
    "recall = recall_score(C_valid, C_valid_model)\n",
    "\n",
    "print(\"Precision = \" + str(precision))\n",
    "print(\"Recall = \" + str(recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dealing with  Class Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pos = np.sum(C_train == 1)\n",
    "num_neg = np.sum(C_train == -1)\n",
    "\n",
    "print(\"# Positively classified data in training set = \" + str(num_pos))\n",
    "print(\"# Negatively classified data in training set = \" + str(num_neg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is how you specify a polynomial kernel\n",
    "rbf_svm_model = SVC(kernel=\"rbf\", class_weight=\"balanced\")\n",
    "\n",
    "# train the model - note we don't have have to form a design matrix\n",
    "rbf_svm_model.fit(X_train, C_train)\n",
    "\n",
    "# Predict validation data\n",
    "C_valid_model = rbf_svm_model.predict(X_valid)\n",
    "\n",
    "precision = precision_score(C_valid, C_valid_model)\n",
    "recall = recall_score(C_valid, C_valid_model)\n",
    "\n",
    "print(\"Precision = \" + str(precision))\n",
    "print(\"Recall = \" + str(recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is how you specify a polynomial kernel\n",
    "poly_svm_model = SVC(kernel=\"poly\", degree=3, class_weight=\"balanced\")\n",
    "\n",
    "# train the model - note we don't have have to form a design matrix\n",
    "poly_svm_model.fit(X_train, C_train)\n",
    "\n",
    "# Predict validation data\n",
    "C_valid_model = poly_svm_model.predict(X_valid)\n",
    "\n",
    "precision = precision_score(C_valid, C_valid_model)\n",
    "recall = recall_score(C_valid, C_valid_model)\n",
    "\n",
    "print(\"Precision = \" + str(precision))\n",
    "print(\"Recall = \" + str(recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data from lecture 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.loadtxt('lec15.txt')\n",
    "num_points = data.shape[0]\n",
    "\n",
    "x = data[:, 0:2]\n",
    "c = data[:, 2]\n",
    "\n",
    "# Use the same training data as past examples\n",
    "num_train = int(num_points*0.8*0.8)\n",
    "X_train = x[0:num_train]\n",
    "C_train = c[0:num_train]\n",
    "\n",
    "# normalize\n",
    "mu_X = np.mean(X_train)\n",
    "sig_X = np.std(X_train)\n",
    "\n",
    "# Let's use SVC with balanced classes\n",
    "rbf_svm_model = SVC(kernel=\"rbf\", class_weight=\"balanced\")\n",
    "\n",
    "# train the model - note we don't have have to form a design matrix\n",
    "rbf_svm_model.fit(X_train_norm, C_train)\n",
    "\n",
    "# Let's use SVC with balanced classes\n",
    "poly_svm_model = SVC(kernel=\"poly\", degree=5, class_weight=\"balanced\")\n",
    "\n",
    "# train the model - note we don't have have to form a design matrix\n",
    "poly_svm_model.fit((X_train-mu_X)/sig_X, C_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------- CLASSIFY ENTIRE PLANE AND PLOT --------\n",
    "# You could ignore this if you wanted\n",
    "\n",
    "\n",
    "# turn 0,1 to color strings just for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "COLORS = ['#F00D2C', '#553C67']\n",
    "c_color = []\n",
    "for i in range(num_points):\n",
    "    c_color.append(COLORS[int(c[i])])\n",
    "\n",
    "# Classify all the points in the plane\n",
    "x1_plot = np.linspace(0, 1, 100)\n",
    "x2_plot = np.linspace(0, 1.3, 100)\n",
    "# Form all combinations from x1_plot and x2_plot\n",
    "xx1, xx2 = np.meshgrid(x1_plot, x2_plot)\n",
    "# Flatten xx1 and xx2 to a list of points\n",
    "x_plot = np.array([xx1.ravel(), xx2.ravel()]).transpose()\n",
    "\n",
    "# classify each point according to each model\n",
    "c_plot_rbf = rbf_svm_model.predict((x_plot - mu_X)/sig_X)\n",
    "c_plot_poly = poly_svm_model.predict((x_plot - mu_X)/sig_X)\n",
    "\n",
    "# put back into matrix form\n",
    "c_plot_rbf = c_plot_rbf.reshape(xx1.shape)\n",
    "c_plot_poly = c_plot_poly.reshape(xx1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot classification at each point as a colored region\n",
    "from matplotlib.colors import ListedColormap\n",
    "plt.pcolormesh(xx1, xx2, c_plot_rbf, cmap=ListedColormap(COLORS))\n",
    "plt.scatter(x[:,0], x[:,1], marker='^', edgecolors='k', linewidth=0.5, c=c_color)\n",
    "plt.xlabel('X1')\n",
    "plt.ylabel('X2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.pcolormesh(xx1, xx2, c_plot_poly, cmap=ListedColormap(COLORS))\n",
    "plt.scatter(x[:,0], x[:,1], marker='^', edgecolors='k', linewidth=0.5, c=c_color)\n",
    "plt.xlabel('X1')\n",
    "plt.ylabel('X2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motivation for tree based classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.loadtxt('lec18.txt')\n",
    "num_points = data.shape[0]\n",
    "X = data[:, 0:2]\n",
    "C = data[:, 2]\n",
    "\n",
    "mu_X = np.mean(X)\n",
    "sig_X = np.std(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cycler import cycler\n",
    "COLORS = ['#553C67', '#F00D2C']\n",
    "default_cycler = cycler(color=COLORS)\n",
    "plt.rc('axes', prop_cycle=default_cycler) \n",
    "plt.rc('text', usetex=True)\n",
    "plt.rc('text.latex', preamble=r'\\usepackage{bm}')\n",
    "\n",
    "I_pos = C == 1\n",
    "I_neg = C == 0\n",
    "\n",
    "\n",
    "# plot points classified as negative\n",
    "plt.scatter(X[I_neg,0], X[I_neg,1],  edgecolors='k', linewidth=0.5)\n",
    "\n",
    "# plot points classified as positive\n",
    "plt.scatter(X[I_pos,0], X[I_pos,1],  edgecolors='k', linewidth=0.5)\n",
    "\n",
    "plt.xlabel('$x_1$')\n",
    "plt.ylabel('$x_2$')\n",
    "plt.title('Data in X space')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is how you specify a polynomial kernel\n",
    "rbf_svm_model = SVC(kernel=\"rbf\", class_weight='balanced')\n",
    "\n",
    "# train the model\n",
    "rbf_svm_model.fit((X-mu_X)/sig_X, C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify all the points in the plane\n",
    "x1_plot = np.linspace(0, 1, 100)\n",
    "x2_plot = np.linspace(0, 1, 100)\n",
    "\n",
    "# Form all combinations from x1_plot and x2_plot\n",
    "xx1, xx2 = np.meshgrid(x1_plot, x2_plot)\n",
    "\n",
    "# Flatten xx1 and xx2 to a list of points\n",
    "x_plot = np.array([xx1.ravel(), xx2.ravel()]).transpose()\n",
    "\n",
    "# classify each point according to each model\n",
    "c_plot_rbf = rbf_svm_model.predict((x_plot-mu_X)/sig_X)\n",
    "\n",
    "# put back into matrix form\n",
    "c_plot_rbf = c_plot_rbf.reshape(xx1.shape)\n",
    "\n",
    "# plot predictions\n",
    "plt.pcolormesh(xx1, xx2, c_plot_rbf, cmap=ListedColormap(COLORS))\n",
    "\n",
    "# plot points classified as negative\n",
    "plt.scatter(X[I_neg,0], X[I_neg,1], edgecolors='k', linewidth=0.5)\n",
    "\n",
    "# plot points classified as positive\n",
    "plt.scatter(X[I_pos,0], X[I_pos,1], edgecolors='k', linewidth=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
